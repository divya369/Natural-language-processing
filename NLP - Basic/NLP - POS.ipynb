{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/divyapatel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import package\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resolve LookupError\n",
    "# Resource punkt not found.\n",
    "#  Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "#  >>> import nltk\n",
    "#  >>> nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infuse your life with action. Don't wait for it to happen. Make it happen. Make your own future.Make your own hope. Make your own love. And whatever your beliefs, honor your creator, not by passivelywaiting for grace to come down from upon high, but by doing what you can to make grace happen... yourself,right now, right down here on Earth.\n"
     ]
    }
   ],
   "source": [
    "text = (\"Infuse your life with action. Don't wait for it to happen. Make it happen. Make your own future.\" \n",
    "        \"Make your own hope. Make your own love. And whatever your beliefs, honor your creator, not by passively\" \n",
    "        \"waiting for grace to come down from upon high, but by doing what you can to make grace happen... yourself,\" \n",
    "        \"right now, right down here on Earth.\")\n",
    "text1 = (\"Hei there. How are you Divya? Mary had a litte lamb. Her hair are short and beautiful? Divya learning Data Science.\"\n",
    "        \" New York is good place to visit. My Relatives are staying in New York. Divya learning Python. Divya learning Android.\"\n",
    "        \" Divya played table tennis when he was in the mood of playing table tennis.\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hei there.', 'How are you Divya?', 'Mary had a litte lamb.', 'Her hair are short and beautiful?', 'Divya learning Data Science.', 'New York is good place to visit.', 'My Relatives are staying in New York.', 'Divya learning Python.', 'Divya learning Android.', 'Divya played table tennis when he was in the mood of playing table tennis.']\n"
     ]
    }
   ],
   "source": [
    "# word_tokenize and sent_tokenize are the functions to break text into works and sentences\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# applying the sentence function\n",
    "sents = sent_tokenize(text1)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hei', 'there', '.'], ['How', 'are', 'you', 'Divya', '?'], ['Mary', 'had', 'a', 'litte', 'lamb', '.'], ['Her', 'hair', 'are', 'short', 'and', 'beautiful', '?'], ['Divya', 'learning', 'Data', 'Science', '.'], ['New', 'York', 'is', 'good', 'place', 'to', 'visit', '.'], ['My', 'Relatives', 'are', 'staying', 'in', 'New', 'York', '.'], ['Divya', 'learning', 'Python', '.'], ['Divya', 'learning', 'Android', '.'], ['Divya', 'played', 'table', 'tennis', 'when', 'he', 'was', 'in', 'the', 'mood', 'of', 'playing', 'table', 'tennis', '.']]\n"
     ]
    }
   ],
   "source": [
    "# applying the word function\n",
    "\n",
    "words = [word_tokenize(sent) for sent in sents]\n",
    "print(words)\n",
    "\n",
    "# same as above \n",
    "# words = []\n",
    "# for sent in sents:\n",
    "#     words.append(word_tokenize(sent))\n",
    "# print(words)\n",
    "\n",
    "# punctuations are also treated as separate tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop words : unnecessary words like has, a, an, was, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/divyapatel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resource stopwords not found.\n",
    "# Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK comes with some built in linguistic resources \n",
    "# among them are collection of stopwords for different language\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation          # from python module\n",
    "customStopWords = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "# we have made set and not list because we don't care about the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hei', 'How', 'Divya', 'Mary', 'litte', 'lamb', 'Her', 'hair', 'short', 'beautiful', 'Divya', 'learning', 'Data', 'Science', 'New', 'York', 'good', 'place', 'visit', 'My', 'Relatives', 'staying', 'New', 'York', 'Divya', 'learning', 'Python', 'Divya', 'learning', 'Android', 'Divya', 'played', 'table', 'tennis', 'mood', 'playing', 'table', 'tennis']\n"
     ]
    }
   ],
   "source": [
    "wordsWOStopwords = []\n",
    "for word in word_tokenize(text1):\n",
    "    if word not in customStopWords:\n",
    "        wordsWOStopwords.append(word)\n",
    "print(wordsWOStopwords)\n",
    "\n",
    "# same as above\n",
    "# wordsOWStopwords = [word for word in word_tokenize(text1) if word not in customStopWords]\n",
    "# print(wordsOWStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Android', 'Divya'), 1),\n",
       " (('Data', 'Science'), 1),\n",
       " (('Divya', 'Mary'), 1),\n",
       " (('Divya', 'learning'), 3),\n",
       " (('Divya', 'played'), 1),\n",
       " (('Hei', 'How'), 1),\n",
       " (('Her', 'hair'), 1),\n",
       " (('How', 'Divya'), 1),\n",
       " (('Mary', 'litte'), 1),\n",
       " (('My', 'Relatives'), 1),\n",
       " (('New', 'York'), 2),\n",
       " (('Python', 'Divya'), 1),\n",
       " (('Relatives', 'staying'), 1),\n",
       " (('Science', 'New'), 1),\n",
       " (('York', 'Divya'), 1),\n",
       " (('York', 'good'), 1),\n",
       " (('beautiful', 'Divya'), 1),\n",
       " (('good', 'place'), 1),\n",
       " (('hair', 'short'), 1),\n",
       " (('lamb', 'Her'), 1),\n",
       " (('learning', 'Android'), 1),\n",
       " (('learning', 'Data'), 1),\n",
       " (('learning', 'Python'), 1),\n",
       " (('litte', 'lamb'), 1),\n",
       " (('mood', 'playing'), 1),\n",
       " (('place', 'visit'), 1),\n",
       " (('played', 'table'), 1),\n",
       " (('playing', 'table'), 1),\n",
       " (('short', 'beautiful'), 1),\n",
       " (('staying', 'New'), 1),\n",
       " (('table', 'tennis'), 2),\n",
       " (('tennis', 'mood'), 1),\n",
       " (('visit', 'My'), 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(wordsWOStopwords)\n",
    "sorted(finder.ngram_fd.items())\n",
    "\n",
    "# collocation () = module\n",
    "# BigramCollocaionFinder = class\n",
    "# from_words = method of class BigramCollocationFinder\n",
    "# finder = object ( not list )\n",
    "# sorted = method of class finder\n",
    "# ngram_fd.items = method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming text - 'played', 'playing' change to 'play'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Divya played table tennis when he was in the mood of playing table tennis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hei', 'how', 'divy', 'mary', 'lit', 'lamb', 'her', 'hair', 'short', 'beauty', 'divy', 'learn', 'dat', 'sci', 'new', 'york', 'good', 'plac', 'visit', 'my', 'rel', 'stay', 'new', 'york', 'divy', 'learn', 'python', 'divy', 'learn', 'android', 'divy', 'play', 'tabl', 'ten', 'mood', 'play', 'tabl', 'ten']\n"
     ]
    }
   ],
   "source": [
    "# st = LancasterStemmer()\n",
    "# stemmedWords = [st.stem(word) for word in word_tokenize(text1)]\n",
    "# print(stemmedWords)\n",
    "\n",
    "st = LancasterStemmer()\n",
    "stemmedWords = [st.stem(word) for word in wordsWOStopwords]\n",
    "print(stemmedWords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Tags to relevent part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/divyapatel/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hei', 'VB'),\n",
       " ('how', 'WRB'),\n",
       " ('divy', 'JJ'),\n",
       " ('mary', 'JJ'),\n",
       " ('lit', 'NN'),\n",
       " ('lamb', 'VBZ'),\n",
       " ('her', 'PRP$'),\n",
       " ('hair', 'NN'),\n",
       " ('short', 'JJ'),\n",
       " ('beauty', 'NN'),\n",
       " ('divy', 'NN'),\n",
       " ('learn', 'VBP'),\n",
       " ('dat', 'NN'),\n",
       " ('sci', 'JJ'),\n",
       " ('new', 'JJ'),\n",
       " ('york', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('plac', 'NN'),\n",
       " ('visit', 'NN'),\n",
       " ('my', 'PRP$'),\n",
       " ('rel', 'NN'),\n",
       " ('stay', 'VB'),\n",
       " ('new', 'JJ'),\n",
       " ('york', 'NN'),\n",
       " ('divy', 'NN'),\n",
       " ('learn', 'VBP'),\n",
       " ('python', 'NN'),\n",
       " ('divy', 'NN'),\n",
       " ('learn', 'VBP'),\n",
       " ('android', 'NN'),\n",
       " ('divy', 'NN'),\n",
       " ('play', 'NN'),\n",
       " ('tabl', 'NN'),\n",
       " ('ten', 'RB'),\n",
       " ('mood', 'VBD'),\n",
       " ('play', 'VB'),\n",
       " ('tabl', 'NNS'),\n",
       " ('ten', 'VB')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(stemmedWords)\n",
    "\n",
    "# VB = verb\n",
    "# NN = noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding word meaning according to the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/divyapatel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.01') the lowest part of the musical range\n",
      "Synset('bass.n.02') the lowest part in polyphonic music\n",
      "Synset('bass.n.03') an adult male singer with the lowest voice\n",
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n",
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
      "Synset('bass.n.06') the lowest adult male singing voice\n",
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n",
      "Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
      "Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets('bass'):\n",
    "    print(ss,ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n"
     ]
    }
   ],
   "source": [
    "sense1 = lesk(word_tokenize(\"Sing in the lower tone, along with the bass.\"),'bass')\n",
    "print(sense1,sense1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('freshwater_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"
     ]
    }
   ],
   "source": [
    "sense2 = lesk(word_tokenize(\"This sea bass was really hard to catch\"),'bass')\n",
    "print(sense1,sense2.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cool.n.01') the quality of being at a refreshingly low temperature\n",
      "Synset('aplomb.n.01') great coolness and composure under strain\n",
      "Synset('cool.v.01') make cool or cooler\n",
      "Synset('cool.v.02') loose heat\n",
      "Synset('cool.v.03') lose intensity\n",
      "Synset('cool.a.01') neither warm nor very cold; giving relief from heat\n",
      "Synset('cool.s.02') marked by calm self-control (especially in trying circumstances); unemotional\n",
      "Synset('cool.a.03') (color) inducing the impression of coolness; used especially of greens and blues and violets\n",
      "Synset('cool.a.04') psychologically cool and unenthusiastic; unfriendly or unresponsive or showing dislike\n",
      "Synset('cool.s.05') (used of a number or sum) without exaggeration or qualification\n",
      "Synset('cool.s.06') fashionable and attractive at the time; often skilled or socially adept\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets('cool'):\n",
    "    print(ss,ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cool.s.06') fashionable and attractive at the time; often skilled or socially adept\n"
     ]
    }
   ],
   "source": [
    "sense3 = lesk(word_tokenize(\"Nowadays, the social reformer is cool and hip.\"),'cool')\n",
    "print(sense3,sense3.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cool.a.04') psychologically cool and unenthusiastic; unfriendly or unresponsive or showing dislike\n"
     ]
    }
   ],
   "source": [
    "sense4 = lesk(word_tokenize(\"We'll talk when you cool off and get yourself together.\"),'cool')\n",
    "print(sense4,sense4.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cool.v.03') lose intensity\n"
     ]
    }
   ],
   "source": [
    "sense5 = lesk(word_tokenize(\"Cool effcts.\"),'cool')\n",
    "print(sense5,sense5.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cool.v.01') make cool or cooler\n"
     ]
    }
   ],
   "source": [
    "sense6 = lesk(word_tokenize(\"We changed into some cooler clothes.\"),'cool')\n",
    "print(sense6,sense6.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cool.a.03') (color) inducing the impression of coolness; used especially of greens and blues and violets\n"
     ]
    }
   ],
   "source": [
    "sense7 = lesk(word_tokenize(\"Carmen wiped Destiny's face and eyes with the cool rag and used a tissue to wipe her nose.\"),'cool')\n",
    "print(sense7,sense7.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
